<html>
    <head>
        <title>A Slideous Show</title> 
        <link rel="stylesheet" type="text/css" href="slideous.css" /> 
        <script src="slideous.js" type="text/javascript"> </script> 
      </head>
<body>

    <div id="statusbar">
        <span style="float:right;">
          <span style="margin-right:4em;font-weight:bold;"><span id="slideidx"></span> of {$slidecount}</span>
          <button id="homebutton" title="first slide">1</button>
          <button id="prevslidebutton" title="previous slide">&laquo;</button>
          <button id="previtembutton" title="previous item">&lsaquo;</button>
          <button id="nextitembutton" title="next item">&rsaquo;</button>
          <button id="nextslidebutton" title="next slide">&raquo;</button>
          <button id="endbutton" title="last slide">{$slidecount}</button>
          <button id="incfontbutton" title="content">A+</button>
          <button id="decfontbutton" title="first slide">A-</button>
          <select id="tocbox" size="1"><option></option></select>
        </span>
        <span id="eos">&frac12;</span>
        <span title="{$location}, {$date}">{$title}, {$author}</span>
      </div>

<div id="why-machine-learning-ml" class="slide section level1">
<h1>Why Machine Learning (ML)</h1>
<ul>
<li>How computers know how to do things?</li>
<li>Two ways:
<ol style="list-style-type: decimal">
<li>programming: steps detailed by human programmer</li>
<li>learning: without being specifically told</li>
</ol></li>
<li>Example 1: machine translation
<ol style="list-style-type: decimal">
<li>programming: writing many rules to replace and reposition words, e.g., <em>Do you speak Julia?</em> <em>Sprechen Sie Julia?</em><br />
</li>
<li>learning: feeding the computer many bilingual documents</li>
</ol></li>
<li>Example 2: sorting
<ol style="list-style-type: decimal">
<li>programming: Quicksort, etc.</li>
<li>learning: feeding the computer many pairs of unsorted and sorted list of numbers.</li>
</ol></li>
<li>The first approach in the context of AI is also called rule-based system or expert system, e.g. MyCin, Grammarly.</li>
</ul>
</div>
<div id="why-ml-is-attractive" class="slide section level1">
<h1>Why ML is attractive</h1>
<ul>
<li>We are lazy. We want to shift the heavy lifting to the computers.</li>
<li>We are incompetent. No kidding! Sometimes it is very difficult to come up with step-by-step instructions.</li>
<li>Examples: Self-driving, AlphaGo, Automated circuit routing, Machine translation, Commonsense reasoning, text entailment, Document generation, auto-reply of messages/emails, <a href="https://www.youtube.com/watch?v=M-QUkgk3HyE">fly a helicoper inversely</a>, <a href="https://blogs.nvidia.com/blog/2016/05/25/deep-learning-paints-videos/">van-Gogh-lize paints</a>.</li>
<li>It is a dream. “Creating an artificial being has been the dream since the beginning of science.” – Movie A.I., Spielberg et al., 2001</li>
</ul>
</div>
<div id="three-types-of-mls" class="slide section level1">
<h1>Three types of MLs</h1>
<p>ML (in current approaches) is about finding/approximating functions.</p>
<ul>
<li>Supervised, finding <span class="math inline"><em>f̂</em>(<em>x</em>) ≈ <em>f</em>(<em>x</em>)</span> with ground truth provided by human.
<ul>
<li>Let <span class="math inline"><em>x</em></span> and <span class="math inline"><em>y</em></span> be two (vectors of) variables, and a function connecting them <span class="math inline"><em>y</em> = <em>f</em>(<em>x</em>)</span> But only god knows <span class="math inline"><em>f</em></span>.</li>
<li>We construct another function <span class="math inline"><em>f̂</em></span> to approximate <span class="math inline"><em>f</em></span> such that <span class="math inline"><em>ŷ</em> = <em>f̂</em>(<em>x</em>) ≈ <em>y</em> = <em>f</em>(<em>x</em>)</span> for a(ny) given <span class="math inline"><em>x</em></span>.</li>
<li><strong>Supervised</strong> because we provide many pairs of <span class="math inline"><em>x</em></span>’s and <span class="math inline"><em>y</em></span>’s for the computer to know the difference between <span class="math inline"><em>ŷ</em></span> and <span class="math inline"><em>y</em></span> on a large pool of samples.</li>
<li>Examples: object detection from images, <a href="http://flavia.sourceforge.net/">Flavia</a>, <a href="https://www.electronicdesign.com/technologies/microprocessors/article/21802106/ai-helps-amds-ryzen-take-on-intel">CPU branch prediction</a>, <a href="https://arxiv.org/abs/2005.06546">COVID-19 diagnosis from blood profile</a>, <a href="https://www.technologyreview.com/2009/04/29/213440/a-neural-net-that-diagnoses-epilepsy/">Epileptic EEG recognition</a>, <a href="https://mfr.osf.io/render?url=https://osf.io/b58jr/?action=download%26mode=render">depression treatment from brain shapes</a>.</li>
<li>Beyond categorization/classification: <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004838">Mflux</a>, <a href="https://www.aclweb.org/anthology/P15-2007.pdf">Review helpfulness prediction</a>, <a href="https://www.aclweb.org/anthology/E17-2112.pdf">Document summarization</a>, predict house prices</li>
</ul></li>
<li>Unsupervised, finding <span class="math inline"><em>f̂</em>(<em>x</em>)</span> without ground truth</li>
<li>Reinforcement, let the machine find ground truth itself</li>
</ul>
</div>
<div id="representation-of-x" class="slide section level1">
<h1>Representation of <span class="math inline"><em>x</em></span></h1>
<ul>
<li><span class="math inline"><em>x</em></span> is usually not a simple (vector of) number(s). How to tell it to a computer?</li>
<li>Example: bananas vs. apples</li>
<li><strong>Feature engineering</strong>: manually craft functions to <strong>extract</strong> features from raw data, e.g,. SIFT, bag-of-words.</li>
<li>Automated feature extraction in deep learing: E.g., filters in CNNs.</li>
<li>If <span class="math inline"><em>x</em></span> involves categorical values (e.g., gender), there are usually two approaches: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"><strong>One-hot encoding</strong></a> and <a href=""><strong>embedding</strong></a> (in DL context, to be discussed later).</li>
</ul>
</div>
<div id="supervised-ml" class="slide section level1">
<h1>Supervised ML</h1>
<ul>
<li>Given many pairs of inputs and outputs: <span class="math inline">{(<strong>X</strong><sub><strong>1</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>1</strong></sub>), (<strong>X</strong><sub><strong>2</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>2</strong></sub>), …, (<strong>X</strong><sub><strong>N</strong></sub><strong>,</strong> <strong>y</strong><sub><strong>N</strong></sub>)}</span>,</li>
<li>that underline a “black-box” function <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> ↦ ℝ<sup><em>m</em></sup></span> such that <span class="math inline">∀<em>i</em> ∈ [1..<em>n</em>], <em>f</em>(<strong>X</strong><sub><em>i</em></sub>) = <strong>y</strong><sub><em>i</em></sub></span>,</li>
<li>construct a function <span class="math inline"><em>f̂</em></span> that approximates the function <span class="math inline"><em>f</em></span>.</li>
<li>“approximate”: usually <span class="math inline">min ||<em>f̂</em>(<em>x</em>) − <em>f</em>(<em>x</em>)||<sup><em>p</em></sup></span> where <span class="math inline"><em>p</em></span> is usually 1 or 2. <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">See <span class="math inline">ℓ<sub><em>p</em></sub></span>-norm</a> . <!-- - In other words, $f$ is a black box. And we need to find $\hat{f}$ that mimick the black box.  --></li>
<li>The process of finding the approximation function <span class="math inline"><em>f̂</em></span> is called <strong>training</strong> or <strong>learning</strong>.</li>
<li><span class="math inline"><em>f̂</em></span> is called a <strong>model</strong> or an <strong>estimator</strong>.</li>
<li><span class="math inline"><strong>X</strong><sub><strong>i</strong></sub></span>: an <strong>input</strong> (especially when raw data is used as the input) or <strong>feature vector</strong> (if using feature engineering).</li>
<li><span class="math inline"><strong>y</strong><sub><strong>i</strong></sub></span>, often <span class="math inline"> ∈ ℝ<sup>1</sup></span> a <strong>label</strong> (in classification) or <strong>target</strong> (used more generally and lately).</li>
<li>Classification vs. Regression: When <span class="math inline"><em>y</em></span> is continuous or discrete. In modern DL context, such division is usually no mentioned, expecially in generative tasks.</li>
</ul>
</div>
</body>
</html>